{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwuDkFZF0KtI"
      },
      "source": [
        "# Blind Source Separation \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwMpfgV9huNU"
      },
      "source": [
        "### Task \n",
        "The task consists in decomposing an image obtained as a sum of a two images img1 and img2 into its components.\n",
        "\n",
        "The network takes in input the sum img1+img2 and returns the predicted components hat_img1 and hat_img2.\n",
        "\n",
        "No preprocessing is allowed. \n",
        "\n",
        "### Data\n",
        "The source images img1 and img2 come from different datasets: mnist and fashion_mnist, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ubxN9iJ5HFl"
      },
      "source": [
        "## Imports\n",
        "The required libraries and classes are included:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DHeENV9A4UD-"
      },
      "outputs": [],
      "source": [
        "#utilities\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import keras as ks\n",
        "import pandas as pd\n",
        "\n",
        "#tensorflow, keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Layer, ReLU\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#plot\n",
        "import plotly.graph_objects as go\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4jyQ7tP6QY8"
      },
      "source": [
        "## Download Data\n",
        "As a first step, the two datasets are loaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2edNKGPyVpq",
        "outputId": "5be02b6f-49d0-4e1a-8dff-f4a0097ed621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "mnist dataset contains 60000 training images and 10000 test images. Each grayscale image with dimension (28, 28)\n",
            "\n",
            "fashion_mnist dataset contains 60000 images for training and 10000 for testing. Each grayscale image with dimension (28, 28)\n"
          ]
        }
      ],
      "source": [
        "(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = mnist.load_data()\n",
        "(fashion_mnist_x_train, fashion_mnist_y_train), (fashion_mnist_x_test, fashion_mnist_y_test) = fashion_mnist.load_data()\n",
        "\n",
        "print(\"mnist dataset contains {} training images and {} test images. Each grayscale image with dimension {}\".format(mnist_x_train.shape[0],mnist_x_test.shape[0],(mnist_x_train.shape[1],mnist_x_train.shape[2])))\n",
        "print()\n",
        "print(\"fashion_mnist dataset contains {} images for training and {} for testing. Each grayscale image with dimension {}\".format(fashion_mnist_x_train.shape[0],fashion_mnist_x_test.shape[0],(fashion_mnist_x_train.shape[1],fashion_mnist_x_train.shape[2])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK4W8ufzezWc"
      },
      "source": [
        "Then we make a normalization and padding step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuY0mA4_60Jf",
        "outputId": "3c12e1b8-1d2b-45ca-de30-8850c806cd30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The dimension of mnist's images after normalization and padding is: \t(32, 32)\n",
            "The dimension of fashion_mnist's images after normalization and padding is: \t(32, 32)\n"
          ]
        }
      ],
      "source": [
        "#normnalize and pad:\n",
        "mnist_x_train = np.pad(mnist_x_train,((0,0),(2,2),(2,2)))/255.\n",
        "mnist_x_test = np.pad(mnist_x_test,((0,0),(2,2),(2,2)))/255.\n",
        "fashion_mnist_x_train = np.pad(fashion_mnist_x_train,((0,0),(2,2),(2,2)))/255.\n",
        "fashion_mnist_x_test = np.pad(fashion_mnist_x_test,((0,0),(2,2),(2,2)))/255.\n",
        "\n",
        "print(\"The dimension of mnist's images after normalization and padding is: \\t{}\".format((mnist_x_train.shape[1],mnist_x_train.shape[2])))\n",
        "print(\"The dimension of fashion_mnist's images after normalization and padding is: \\t{}\".format((fashion_mnist_x_train.shape[1],fashion_mnist_x_train.shape[2])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVYDQ0NYCAGH"
      },
      "source": [
        "The train set of the two datasets is split such that 10% of the train set is assigned as the validation set and the rest, 90%, is used for the training purpose. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEEL_3FMEMbW",
        "outputId": "7581dc28-cd83-45e7-dd13-3a8ab183f43f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mnist Training set: 54000 images \n",
            "Mnist Validation_set: 6000 images \n",
            "\n",
            "Fashion_mnist Training set: 54000 images \n",
            "Fashion_mnist Validation_set: 6000 images \n"
          ]
        }
      ],
      "source": [
        "mnist_x_train, mnist_x_val, mnist_y_train, mnist_y_val= train_test_split(mnist_x_train,mnist_y_train,test_size=0.1, random_state= 42) \n",
        "fashion_mnist_x_train, fashion_mnist_x_val, fashion_mnist_y_train, fashion_mnist_y_val= train_test_split(fashion_mnist_x_train,fashion_mnist_y_train,test_size=0.1, random_state= 42)\n",
        "\n",
        "print(\"Mnist Training set: {} images \\nMnist Validation_set: {} images \".format(mnist_x_train.shape[0], mnist_x_val.shape[0]))\n",
        "print()\n",
        "print(\"Fashion_mnist Training set: {} images \\nFashion_mnist Validation_set: {} images \".format(fashion_mnist_x_train.shape[0], fashion_mnist_x_val.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skLsbs1RW8LA"
      },
      "source": [
        "Defining the datagenerator that creates the input and the label images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UtC3d9gN6eiM"
      },
      "outputs": [],
      "source": [
        "def datagenerator(x1,x2,batchsize):\n",
        "    n1 = x1.shape[0]\n",
        "    n2 = x2.shape[0]\n",
        "    while True:\n",
        "        num1 = np.random.randint(0, n1, batchsize)\n",
        "        num2 = np.random.randint(0, n2, batchsize)\n",
        "\n",
        "        x_data = (x1[num1] + x2[num2]) / 2.0\n",
        "        y_data = np.concatenate((x1[num1], x2[num2]), axis=2)\n",
        "\n",
        "        yield x_data, y_data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwIrzbJocxAq"
      },
      "source": [
        "Creation of the three generators, respectively for training,test and the validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9oH4um-jEBCF"
      },
      "outputs": [],
      "source": [
        "#datagenerator for training,validation and test:\n",
        "\n",
        "batchsize = 128\n",
        "inputShape = (32,32,1)\n",
        "\n",
        "train_generator = datagenerator(mnist_x_train,fashion_mnist_x_train,batchsize)\n",
        "test_generator = datagenerator(mnist_x_test,fashion_mnist_x_test,20000)\n",
        "val_generator = datagenerator(mnist_x_val,fashion_mnist_x_val,batchsize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sli9gHCCEY_6"
      },
      "source": [
        "## Visualization\n",
        "Show how the two images randomly generated look like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "ZuuVyCFiEWEi",
        "outputId": "db96f679-b296-46cc-e2dc-ceedb0344abc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAP/klEQVR4nO3dbYxUdZbH8e8RQZcHHRC300KvLUjiU0ZQYtAoYR1H0RBRY4wma0g022YzJmOy+4KwcQf3hZnZjE7mhXFlVjKscR0dHSMZ1x1cYgKrkQFcQB7EwUmDYANOxAA+seDZF3XJNmz9b1VX3XuL5vw+Saer/6du1eHSv75V91/3XnN3ROT0d0anGxCRaijsIkEo7CJBKOwiQSjsIkEo7CJBnNnOwmY2F/g5MAL4F3f/cYP7a55PpGTubvXGrdV5djMbAXwIfB/YDawF7nP3rTnLKOwiJUuFvZ2X8dcAO9z9j+5+BPgVML+NxxORErUT9knAx4N+3p2NicgpqK337M0wsz6gr+znEZF87YR9D9Az6OfJ2dgJ3H0JsAT0nl2kk9p5Gb8WmGZmF5nZKOBeYHkxbYlI0Vresrv7UTN7GPgdtam3pe6+pbDORKRQLU+9tfRkehkvUroypt5EZBhR2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJo6yquZtYPHAKOAUfdfWYRTYlI8Yq4ZPNfuvufCngcESmRXsaLBNFu2B1YYWbrzayviIZEpBztvoy/3t33mNmfA2+a2QfuvmrwHbI/AvpDINJhhV2y2cwWA4fd/ac599Elm0VKVvglm81sjJmNO34buBnY3OrjiUi52nkZ3wW8ambHH+ff3P0/CulKRApX2Mv4pp5ML+NFSlf4y3gRGV4UdpEgFHaRIBR2kSAUdpEgijgQRuS0Mnbs2GTt8OHDFXZSLG3ZRYJQ2EWCUNhFglDYRYJQ2EWC0N54GfZGjBiRrHV3d9cdv+WWW5LL9Pb2JmuPPvpo032darRlFwlCYRcJQmEXCUJhFwlCYRcJQmEXCUJTb5Jr1qxZydqYMWMq6+Oiiy5K1saNG5esTZw4ccjPtWvXriEvMxxoyy4ShMIuEoTCLhKEwi4ShMIuEoTCLhJEw6k3M1sKzAP2u/sV2dgE4EWgF+gH7nH3A+W1KZ1y6aWXJmsXX3xxhZ2kHTlyJFnr7++vO75jx47kMm+//Xa7LZ2Smtmy/xKYe9LYQmClu08DVmY/i8gprGHYs+utf3bS8HxgWXZ7GXBHwX2JSMFafc/e5e4D2e291K7oKiKnsLY/Luvunnd1VjPrA/rafR4RaU+rW/Z9ZtYNkH3fn7qjuy9x95nuPrPF5xKRArQa9uXAguz2AuC1YtoRkbI0M/X2AjAHmGhmu4EfAT8GXjKzB4GdwD1lNinNO/fcc+uOX3nllcllVq1aNeTHayQ1tfXZZyfv6/0/e/bsSdZSU2iQf0mmr7/+OlmLpmHY3f2+ROl7BfciIiXSJ+hEglDYRYJQ2EWCUNhFglDYRYLQCScLYGbJmnvyw4W5rr766mRt8uTJydqBA/UPPrz88suTyyxbtixZW758ebL22GOPJWt5U2wRlfE7MlTasosEobCLBKGwiwShsIsEobCLBKGwiwShqbcCtDp1Mm/evGTtzDPT/zVr1qxJ1i688MK647fffntymbzroU2bNi1Zq9L555+frN10003J2siRI+uOf/vtt8ll8qY2N27cmKy98cYbydoZZ6S3q8eOHUvWiqQtu0gQCrtIEAq7SBAKu0gQCrtIENobX4C8g0ymTp2arH3yySfJ2rp165K10aNHJ2upyzVdcMEFyWXyzu+WdymkvD38r776at3xu+66K7lMT09PspZ3YM3Ro0eTtdSe7ry98QMDA8naF198kazlyXu+qmjLLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoQ1OojDzJYC84D97n5FNrYY+Gvg0+xui9z93xs+Wc7VXoeDm2++ue742WefnVxmxYoVyVqrlya6//77k7VLLrlkyI/30EMPJWtffvllspY3DTV27Ni642vXrk0u89RTTyVrO3fuTNY+/fTTZO3IkSN1x7/66qvkMsOdu9c94V0zW/ZfAnPrjP/M3adnXw2DLiKd1TDs7r4K0KlCRYa5dt6zP2xmm8xsqZmNL6wjESlFq2F/GpgKTAcGgCdSdzSzPjNbZ2bpz3+KSOlaCru773P3Y+7+LfAL4Jqc+y5x95nuPrPVJkWkfS2F3cy6B/14J7C5mHZEpCwNj3ozsxeAOcBEM9sN/AiYY2bTAQf6gfTcTYe0ermdrq6uZG3OnDl1xxctWtR0X81KTV1B8eeFe+aZZ5K1Vv9tn3/+ed3x7du3J5dZuXJlS88lzWkYdne/r87wsyX0IiIl0ifoRIJQ2EWCUNhFglDYRYJQ2EWCaHjUW6FP1uJRb6lptDJ6Hz8+/cnf1Ekbt2zZklwm77I/rZ6EMO/yRKl1cujQoZaeK8/zzz+frN166611x9evX59c5oYbbkjWUkevyf/XzlFvInIaUNhFglDYRYJQ2EWCUNhFglDYRYIYFtd6q3J6MG+KJ+9ItJQyrvG1e/fuQh8v7wjB1JF+AJs3p49snj17dt3xvGvYPfDAA8na6tWrk7W8/5dWrs2W93h5U7OjRo1K1vLW8TvvvFN3fP/+/cllWqEtu0gQCrtIEAq7SBAKu0gQCrtIEMPiQJienp664zNnpk9Ym/fvyttDPm7cuGQtdQDKjh07ksuMGTMmWfvmm2+StVYP/Ej9u88777zkMjfeeGOydu211yZrH3/8cbL28ssv1x3/4IMPksuMGDEiWcs7kGf06NHJWmov+DnnnJNcZteuXcla3kFPeXvx89Z/aj22evCSDoQRCU5hFwlCYRcJQmEXCUJhFwlCYRcJouHUm5n1AP8KdFG73NMSd/+5mU0AXgR6qV0C6h53P9DgsVqaeksdYDBlypTkMnnnfsur9fb2JmupSxodPHgwuUzeNN/Ro0eTtTx503JTp06tOz5v3rzkMnnr48MPP0zWnnvuuWQtta7KkHdOvlmzZtUdz1v3ebUDB9K/4nnL5U3Lpabz9u7dm1wmTztTb0eBv3X3y4BZwA/M7DJgIbDS3acBK7OfReQU1TDs7j7g7u9ltw8B24BJwHxgWXa3ZcAdZTUpIu0b0nt2M+sFZgBrgC53H8hKe6m9zBeRU1TTJ68ws7HAK8Aj7n5w8McQ3d1T78fNrA/oa7dREWlPU1t2MxtJLejPu/tvsuF9Ztad1buBuqfVcPcl7j7T3dMfZBeR0jUMu9U24c8C29z9yUGl5cCC7PYC4LXi2xORojQz9XY9sBp4Hzg+j7SI2vv2l4C/AHZSm3r7rMFjVXeIXYsef/zxZC01FbJq1arkMjt37kzWurrSuznyjpLKO59Z6rJLeUfYvfvuu8naihUrkjU5NaWm3hq+Z3f3/wJSv13fa6cpEamOPkEnEoTCLhKEwi4ShMIuEoTCLhLEsDjhZJXuvvvuZG3GjBkVdpKWdyTd1q1b646//vrryWXyjtqT4UcnnBQJTmEXCUJhFwlCYRcJQmEXCUJhFwlCU28nyTuibPz48XXHJ06cmFzmuuuuS9bOOuusZG379u3JWn9/f0s1iUFTbyLBKewiQSjsIkEo7CJBKOwiQWhvvMhpRnvjRYJT2EWCUNhFglDYRYJQ2EWCUNhFgmjmWm89ZvaWmW01sy1m9sNsfLGZ7TGzDdnXbeW3KyKtauZab91At7u/Z2bjgPXAHcA9wGF3/2nTT6Z5dpHStXOttwFgILt9yMy2AZOKbU9Eyjak9+xm1gvMoHYFV4CHzWyTmS01s/oHe4vIKaHpsJvZWOAV4BF3Pwg8DUwFplPb8j+RWK7PzNaZ2boC+hWRFjX12XgzGwn8Fviduz9Zp94L/Nbdr2jwOHrPLlKylj8bb7XzND0LbBsc9GzH3XF3ApvbbVJEytPM3vjrgdXA+8Dx6w4tAu6j9hLegX7goWxnXt5jacsuUrLUll2HuIqcZnSIq0hwCrtIEAq7SBAKu0gQCrtIEAq7SBAKu0gQCrtIEAq7SBAKu0gQCrtIEAq7SBAKu0gQCrtIEAq7SBAKu0gQCrtIEAq7SBAKu0gQCrtIEAq7SBAKu0gQCrtIEAq7SBAKu0gQzVzr7Wwz+72ZbTSzLWb2WDZ+kZmtMbMdZvaimY0qv10RaVUzW/ZvgBvd/Upq13aba2azgJ8AP3P3i4EDwIPltSki7WoYdq85nP04Mvty4Ebg5Wx8GXBHKR2KSCGaes9uZiPMbAOwH3gT+Aj43N2PZnfZDUwqp0URKUJTYXf3Y+4+HZgMXANc0uwTmFmfma0zs3Ut9igiBRjS3nh3/xx4C7gW+I6ZnZmVJgN7EssscfeZ7j6zrU5FpC3N7I0/38y+k93+M+D7wDZqob87u9sC4LWymhSR9pm759/B7LvUdsCNoPbH4SV3/0czmwL8CpgA/DfwV+7+TYPHyn8yEWmbu1u98YZhL5LCLlK+VNj1CTqRIBR2kSAUdpEgFHaRIBR2kSDObHyXQv0J2Jndnpj93Gnq40Tq40TDrY8LU4VKp95OeGKzdafCp+rUh/qI0odexosEobCLBNHJsC/p4HMPpj5OpD5OdNr00bH37CJSLb2MFwmiI2E3s7lmtj07WeXCTvSQ9dFvZu+b2YYqT65hZkvNbL+ZbR40NsHM3jSzP2Tfx3eoj8VmtidbJxvM7LYK+ugxs7fMbGt2UtMfZuOVrpOcPipdJ6Wd5NXdK/2idqjsR8AUYBSwEbis6j6yXvqBiR143tnAVcDmQWP/BCzMbi8EftKhPhYDf1fx+ugGrspujwM+BC6rep3k9FHpOgEMGJvdHgmsAWYBLwH3ZuP/DPzNUB63E1v2a4Ad7v5Hdz9C7Zj4+R3oo2PcfRXw2UnD86mdNwAqOoFnoo/KufuAu7+X3T5E7eQok6h4neT0USmvKfwkr50I+yTg40E/d/JklQ6sMLP1ZtbXoR6O63L3gez2XqCrg708bGabspf5pb+dGMzMeoEZ1LZmHVsnJ/UBFa+TMk7yGn0H3fXufhVwK/ADM5vd6Yag9ped2h+iTngamErtGgEDwBNVPbGZjQVeAR5x94ODa1Wukzp9VL5OvI2TvKZ0Iux7gJ5BPydPVlk2d9+Tfd8PvEptpXbKPjPrBsi+7+9EE+6+L/tF+xb4BRWtEzMbSS1gz7v7b7LhytdJvT46tU6y5x7ySV5TOhH2tcC0bM/iKOBeYHnVTZjZGDMbd/w2cDOwOX+pUi2nduJO6OAJPI+HK3MnFawTMzPgWWCbuz85qFTpOkn1UfU6Ke0kr1XtYTxpb+Nt1PZ0fgT8fYd6mEJtJmAjsKXKPoAXqL0c/B9q770eBM4DVgJ/AP4TmNChPp4D3gc2UQtbdwV9XE/tJfomYEP2dVvV6ySnj0rXCfBdaidx3UTtD8s/DPqd/T2wA/g1cNZQHlefoBMJIvoOOpEwFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEgFHaRIP4XWdmIcbsCsTQAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADICAYAAADx97qTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARmElEQVR4nO3de6yV1Z3G8ecREPFSi4qIqIMXKm2MxQaR2mq9VsYQW42xmknrGOxpYo04MelYxzqOnbQdLy3+MRqZkdFJnNpOrZYQq6JDQ6elULAggrU6ghHkYhUvoFXR3/yxX5LjWetw9tm3wzrn+0lOzt7P2ft91zpsfry8633XckQIAFCePQa6AQCAxlDAAaBQFHAAKBQFHAAKRQEHgEJRwAGgUE0VcNvTbT9r+3nb17aqUQCAvrnR68BtD5P0J0lnS1ov6feSLomINbt4DxedA0D//TkixvQMmzkCnyrp+Yh4ISLek3S/pC81sT0AQN6LubCZAj5e0kvdnq+vMgBABwxv9w5sd0nqavd+AGCoaaaAb5B0eLfnh1XZR0TEHElzJM6BA0ArNXMK5feSJto+0vaeki6WNK81zQIA9KXhI/CI2GH7SkmPShomaW5ErG5ZywAAu9TwZYQN7YxTKADQiOURMaVnyJ2YAFAoCjgAFIoCDgCFooADQKEo4ABQKAo4ABSKAg4AhaKAA0ChKOAAUCgKOAAUigIOAIWigANAoSjgAFAoCjgAFIoCDgCFooADQKEo4ABQqKZWpbe9TtJbkj6QtCO3YgQAoD2aKuCV0yPizy3YDgCgHziFAgCFaraAh6THbC+33dWKBgEA6tPsKZTPR8QG2wdLWmD7jxGxqPsLqsJOcQeAFnNEtGZD9o2StkXErbt4TWt2BgBDy/LcRSINn0KxvY/t/XY+lvRFSU833j4AQH80cwplrKQHbe/czn9FxCMtaRUAoE8NF/CIeEHSp1vYFgBAP3AZIQAUigIOAIWigANAoVpxKz3Qb4ccckiSbdq0aQBaApSLI3AAKBQFHAAKRQEHgEJRwAGgUAxioiEjR45MssmTJ2df+/3vfz/JTjnllCQbMWJE8w0DhhCOwAGgUBRwACgUBRwACkUBB4BCMYhZsKuuuirJDjzwwJbv59RTT02y8ePHJ9kxxxxT9zYXL17cVJsAcAQOAMWigANAoSjgAFAoCjgAFKrPQUzbcyXNkLQlIo6rsgMk/UTSBEnrJF0UEVvb10zknHfeeUl2xhlndGTf27dvT7Jf//rX2dcuWLAgyWbPnt3yNgFDTT1H4PdImt4ju1bSExExUdIT1XMAQAf1WcAjYpGk13rEX5J0b/X4XklfbnG7AAB9aPQ68LERsbF6vEnS2N5eaLtLUleD+wEA9KLpG3kiImzHLn4+R9IcSdrV6wAA/dPoVSibbY+TpOr7ltY1CQBQj0aPwOdJulTSD6rvv2hZi1C3Qw89tK7X5a4CWbt2bfa1y5cvT7JFixYl2ZYt6b/ZW7dyIdJgcsQRRyTZxRdfnGQ333xzJ5oj20kWMbT/U9/nEbjtH0taLOlY2+ttz1StcJ9t+zlJZ1XPAQAd1OcReERc0suPzmxxWwAA/cCdmABQKAo4ABTKnRwE4DLCvu2zzz7ZfOnSpUk2adKkJPvEJz6RZC+88EKSDfXBnxLkBu322CN/zPXBBx/Utc3LLrssyU466aTsa3Ofm+nTe96ULY0ZMybJzj777CTbtGlTPU0s3rBhw5Ks3j+fXVgeEVN6hhyBA0ChKOAAUCgKOAAUigIOAIViUeMBNHr06CR74IEHsq/NDU5+97vfTbKXX345yRiwLFPuz60/g2G33357ku21115Jduedd2bf/8lPfjLJXnzxxSTLDWLm5ob/whe+kN1P7jNbr9xAviTddNNNSTZq1Kgky/0+TzzxxOw277///iS75pprkmz48LSstmAQM4sjcAAoFAUcAApFAQeAQlHAAaBQDGJ2yEEHHZRk9913X5Kddtpp2fc/8sgjSXbbbbcl2TvvvNP/xqGjmpkW9fzzz8/mZ511VpKtXLkyyebMmVPXfiRpxYoVSTZt2rQk23vvvZMs18e5c+dm9/P1r3+9rtdOnTo1yXJ3i0r5vwc7duxIsvfffz/Jcr83Sdq8eXM2r2c/ud+H1PwFBhyBA0ChKOAAUCgKOAAUigIOAIWqZ0m1uba32H66W3aj7Q22V1Rf57a3mQCAnvqcD9z2qZK2SfrPiDiuym6UtC0ibu3XzobwfODz5s1LshkzZtT9/tWrVydZM1ecrFu3LptfdNFFDW8TH9XslQff+973kmz//ffPvvb6669Psk4tMv3aa68l2fbt25Ps1Vdfzb5/3LhxSfboo48mWW4h7sWLF2e3uWbNmqba1Iw2Lb7c2HzgEbFIUvonBAAYUM2cA7/S9lPVKZZ0VqaK7S7by2wva2JfAIAeGi3gd0o6WtJkSRslpXeUVCJiTkRMyR3+AwAa11ABj4jNEfFBRHwo6d8kpbdIAQDaqq5FjW1PkDS/2yDmuIjYWD3+O0knRcTFdWxnSAxiHnLIIUmWm0d5xIgRnWhO1l/+8pdsnrstGo3JLW4r5eeGPu6445Js1apVSdbbwGhOmwbT6pJbwLi3tucG1M8888wk27ZtW9PtKlh2ELPPuVBs/1jSaZIOsr1e0j9KOs32ZEkhaZ2kb7S0qQCAPvVZwCPikkx8dxvaAgDoB+7EBIBCUcABoFDMB94GuQGcU045Jck+/PDDut7bH7k78rq6upLsl7/8ZVP7Gcr22CM97ml2AeLcAN2FF15Y9/tzA+K5ua47JTeQv3Dhwuxrjz766CT77W9/m2Qnn3xykg3xgU2OwAGgVBRwACgUBRwACkUBB4BCMYjZIUuXLm35Nr/zne8k2eWXX17Xe6+77rpWN2fIyA0+N+vtt99OsoMPPrju9w/kgGXujtPcAO4555yTff/vfve7JDv22GOT7LHHHkuyW265JbvN3CDqK6+8kmS5tucWIJfyg62jRo2qa5uzZ8/ObjM37W1/cAQOAIWigANAoSjgAFAoCjgAFIoCDgCFqms+8JbtbIjMB96MSZMmZfMbbrghyb7yla8k2YYNG5Ls0ksvTbJf/epX2f108vNQqmnTpiXZzJkzk6y33+WOHTuSLLew75Qp6SJWjz/+eHabuSsncreZ56526U2unbksZ8yYMUmW+2xK+XnC33rrrSQbOXJkkm3cuDG7zdzvIzcFQu733ttCyQ8++GCS5a4UmjhxYpItWbIku82XX345m2c0tqgxAGD3RAEHgEJRwAGgUH0WcNuH215oe43t1bZnVfkBthfYfq76Prr9zQUA7NTnIKbtcZLGRcSTtveTtFzSlyX9raTXIuIHtq+VNDoi/r6PbQ3YCNmMGTOyeW7+7WXLlrV8/7mBmgsuuCDJ7rrrruz7P/axjyXZb37zm7q2uXXr1nqaiDrtu+++SXb66acn2fDh+ZkqcnN3v/7660n23nvvJVnuFnEpf3t/buHq3N/33ubUfuONN5IsNwj6zjvvJFluELK3AdA333wzmzdj6tSpSXbFFVck2bvvvltXJklr165NstzveOzYsUmWGwCVpJUrV2bzjMYGMSNiY0Q8WT1+S9IzksZL+pKke6uX3ataUQcAdEi/zoHbniDpBElLJI2NiJ3X8GySlP6zAwBom7pnI7S9r6QHJF0dEW92PyUQEdHb6RHbXZLSNb0AAE2p6wjc9gjVivd9EfHzKt5cnR/feZ58S+69ETEnIqbkzt8AABpXzyCmVTvH/VpEXN0tv0XSq90GMQ+IiG/1sa0BG8TsrZ+rVq1KsltvvTXJFi1alGTHH398dpu5eYNzcwTffPPNSdbbgM4dd9yRZMzpDQwZ2UHMek6hfE7SVyWtsr2iyq6T9ANJP7U9U9KLki5qVUsBAH3rs4BHxP9KSq+Bqzmztc0BANSLOzEBoFAUcAAo1JCZTvaee+7J5l/72tc6sv/c7/mhhx5KslmzZmXfv379+pa3CUAxmE4WAAYTCjgAFIoCDgCFooADQKEo4ABQqCFzFUpuQVNJOuqoo5IstyjpVVddlWS5Obol6eGHH06y3NzdvS0sDAA9cBUKAAwmFHAAKBQFHAAKRQEHgEINmUFMACgYg5gAMJhQwAGgUBRwAChUnwXc9uG2F9peY3u17VlVfqPtDbZXVF/ntr+5AICd6lkTc4ekayLiSdv7SVpue0H1sx9FRLoCMACg7epZE3OjpI3V47dsPyNpfLsbBgDYtX6dA7c9QdIJkpZU0ZW2n7I91/boFrcNALALdRdw2/tKekDS1RHxpqQ7JR0tabJqR+i39fK+LtvLbC9rQXsBAJW6buSxPULSfEmPRsQPMz+fIGl+RBzXx3a4kQcA+q+xG3lsW9Ldkp7pXrxtj+v2svMlPd2KVgIA6lPPVSifk/RVSatsr6iy6yRdYnuypJC0TtI32tJCAEAWc6EAwO6PuVAAYDChgANAoSjgAFAoCjgAFIoCDgCFooADQKEo4ABQKAo4ABSKAg4AhaKAA0ChKOAAUCgKOAAUigIOAIWigANAoSjgAFAoCjgAFIoCDgCFqmdNzL1sL7W90vZq2/9U5UfaXmL7eds/sb1n+5sLANipniPwdyWdERGfljRZ0nTb0yT9i6QfRcQxkrZKmtm+ZgIAeuqzgEfNturpiOorJJ0h6WdVfq+kL7elhQCArLrOgdseVq1Iv0XSAkn/J+n1iNhRvWS9pPHtaSIAIKeuAh4RH0TEZEmHSZoqaVK9O7DdZXuZ7WUNthEAkNGvq1Ai4nVJCyV9VtLHbQ+vfnSYpA29vGdOREyJiClNtRQA8BH1XIUyxvbHq8ejJJ0t6RnVCvmF1csulfSLdjUSAJAa3vdLNE7SvbaHqVbwfxoR822vkXS/7X+W9AdJd7exnQCAHhwRnduZ3bmdAcDgsTx3Gpo7MQGgUBRwACgUBRwAClXPIGYr/VnSi9Xjg6rngwX92f0Ntj7Rn91bK/vzV7mwo4OYH9mxvWwwXRtOf3Z/g61P9Gf31on+cAoFAApFAQeAQg1kAZ8zgPtuB/qz+xtsfaI/u7e292fAzoEDAJrDKRQAKFTHC7jt6bafrZZiu7bT+28F23Ntb7H9dLfsANsLbD9XfR89kG3sD9uH215oe021bN6sKi+yT4N1GcBqXv4/2J5fPS+9P+tsr7K9Yud006V+5iTJ9sdt/8z2H20/Y/uz7e5PRwt4NSHWv0r6a0mfknSJ7U91sg0tco+k6T2yayU9ERETJT1RPS/FDknXRMSnJE2T9M3qz6XUPg3WZQBnqTYT6E6l90eSTo+Iyd0utyv1MydJt0t6JCImSfq0an9W7e1PRHTsS7V5xB/t9vzbkr7dyTa0sC8TJD3d7fmzksZVj8dJenag29hE336h2rTBxfdJ0t6SnpR0kmo3VQyv8o98Fnf3L9Xm3H9CtaUM50tyyf2p2rxO0kE9siI/c5L2l7RW1bhip/rT6VMo4yW91O35YFqKbWxEbKweb5I0diAb0yjbEySdIGmJCu7TIFwGcLakb0n6sHp+oMruj1RbW/cx28ttd1VZqZ+5IyW9Iuk/qtNc/257H7W5PwxitkHU/rkt7vIe2/tKekDS1RHxZvefldanaGIZwN2N7RmStkTE8oFuS4t9PiI+o9op1W/aPrX7Dwv7zA2X9BlJd0bECZK2q8fpknb0p9MFfIOkw7s973UptgJttj1OkqrvWwa4Pf1ie4Rqxfu+iPh5FRfdJ6mxZQB3Q5+TdJ7tdZLuV+00yu0qtz+SpIjYUH3fIulB1f6hLfUzt17S+ohYUj3/mWoFva396XQB/72kidXo+Z6SLpY0r8NtaJd5qi0tJxW2xJxtq7ai0jMR8cNuPyqyT4NtGcCI+HZEHBYRE1T7O/M/EfE3KrQ/kmR7H9v77Xws6YuSnlahn7mI2CTpJdvHVtGZktao3f0ZgJP950r6k2rnJP9hoAcfGuzDjyVtlPS+av/yzlTtnOQTkp6T9LikAwa6nf3oz+dV+6/dU5JWVF/nltonScertszfU6oVhRuq/ChJSyU9L+m/JY0c6LY20LfTJM0vvT9V21dWX6t31oJSP3NV2ydLWlZ97h6SNLrd/eFOTAAoFIOYAFAoCjgAFIoCDgCFooADQKEo4ABQKAo4ABSKAg4AhaKAA0Ch/h/Ot8jqXSlogQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "x, y = next(train_generator)\n",
        "plt.imshow(x[0],cmap='gray', interpolation='nearest',)\n",
        "plt.show()\n",
        "plt.imshow(y[0], cmap='gray', interpolation='nearest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEsOxcLBZPsO"
      },
      "source": [
        "# MODEL\n",
        "\n",
        "The U-Net is an elegant architecture and is maybe the most known network architecture used for segmentation. It uses the concept of fully convolutional networks for this approach and its intent is to capture both the features of the context as well as the localization. The main idea of the implementation is to utilize successive contracting layers, which are immediately followed by the upsampling operators for achieving higher resolution outputs on the input images.\n",
        "\n",
        "So, as a first attempt I tried using a single U-Net taking the cue from the **03/05/2022 Segmentation Laboratory** since the given task looks like an image segmentation problem. However, since we want as ouput an image that is a concatenation of two images coming from different datasets, the idea that led to better results was to use two U-Net in parallel where each of them  focuses on classify and localize pixels coming from a specific dataset (mnist and fashion_mnist) and then the two outputs, coming from the two U-Net are concatenated in order to produce the final 32x64 image composed by the images of the respective datasets.\n",
        "\n",
        "After several attempts, I decided to slightly modify the U-Net networks. In particular:\n",
        "\n",
        "* Another 2 convolution layers per floor have been added (instead of the original 2) for a total of 4 convolution layers for each floor.\n",
        "\n",
        "* After the four convolution layers per floor, a batchnormalization layer has been added, to make the network more stable and speed up the convergence time.\n",
        "\n",
        "These changes from the original model were made to gain the best outcomes possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BQTugeTVdsgU"
      },
      "outputs": [],
      "source": [
        "def build_unet(input, n_ch=32, L=4, conv_per_L=2):\n",
        "    \n",
        "    # ENCODER\n",
        "    backup_layers = []\n",
        "    h = input\n",
        "    for l in range(L):\n",
        "\n",
        "        # Each floor in the descent phase\n",
        "        for c in range(conv_per_L):\n",
        "            h = ks.layers.Conv2D(n_ch, 3, 1, padding='same')(h)\n",
        "            h = ks.layers.ReLU()(h)\n",
        "\n",
        "        h = layers.BatchNormalization()(h, training=False)\n",
        "            \n",
        "        if l < L-1:\n",
        "            # Downsample\n",
        "            backup_layers.append(h) \n",
        "            h = ks.layers.MaxPool2D(padding='same')(h)\n",
        "\n",
        "            # Update the channels\n",
        "            n_ch = n_ch * 2\n",
        "\n",
        "    \n",
        "    # DECODER\n",
        "    for l in range(L-1):\n",
        "        # Reduce the channels\n",
        "        n_ch = n_ch // 2\n",
        "\n",
        "        # Upsample\n",
        "        h = ks.layers.Conv2DTranspose(n_ch,2, 2, padding='same')(h)\n",
        "\n",
        "        # Concatenate\n",
        "        h = ks.layers.concatenate([h, backup_layers.pop(-1)])\n",
        "        \n",
        "        # Each floor in the up phase\n",
        "        for c in range(conv_per_L):\n",
        "            h = ks.layers.Conv2D(n_ch, 3, 1, padding='same')(h)\n",
        "            h = ks.layers.ReLU()(h)\n",
        "        \n",
        "        h = layers.BatchNormalization()(h, training=False)\n",
        "        \n",
        "    # Output\n",
        "    y = ks.layers.Conv2D(1, 1)(h)\n",
        "    \n",
        "    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv-fKip_F-w9"
      },
      "source": [
        "In this case we start with an imput image 32x32x1 and we apply a certain number of filters, whose value is set to 64, n_ch=64. As said above, the 4 convolutional layers per floor, each followed by a ReLu activation layer so that all the negative values are not passed to the next layer, are followed along by the Batch Normalization layer. This is done for a total of 3 floors. \n",
        "Then after creating the two nets, their outputs are Concatenated and then the model is builted.\n",
        "As optimizer, Adam was used as it is a common choice and as loss function I used the mean absolute error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "hMNp5ec4fH-V"
      },
      "outputs": [],
      "source": [
        "x = ks.layers.Input(shape=inputShape,name='input')\n",
        "y1 = build_unet(x,n_ch=64,L=3,conv_per_L=4)\n",
        "y2 = build_unet(x,n_ch=64,L=3,conv_per_L=4)\n",
        "double_unet = layers.Concatenate(axis=2)([y1,y2])\n",
        "model = ks.Model(x,double_unet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rxSkfIm_fI9E",
        "outputId": "246d346a-0f76-493a-a493-7b1b8e90237f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 32, 32, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 32, 32, 64)   640         ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 32, 32, 64)   640         ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_40 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_43[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 32, 32, 64)   36928       ['re_lu_20[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 32, 32, 64)   36928       ['re_lu_40[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_23[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_41 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_44[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 32, 32, 64)   36928       ['re_lu_21[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 32, 32, 64)   36928       ['re_lu_41[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_22 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_24[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_42 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_45[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 32, 32, 64)   36928       ['re_lu_22[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 32, 32, 64)   36928       ['re_lu_42[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_23 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_43 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 32, 32, 64)  256         ['re_lu_23[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 32, 32, 64)  256         ['re_lu_43[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 64)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 64)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 16, 16, 128)  73856       ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 16, 16, 128)  73856       ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " re_lu_24 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_44 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_47[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 128)  147584      ['re_lu_24[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 16, 16, 128)  147584      ['re_lu_44[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_25 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_27[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_45 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_48[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 128)  147584      ['re_lu_25[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 16, 16, 128)  147584      ['re_lu_45[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_26 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_28[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_46 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 16, 16, 128)  147584      ['re_lu_26[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 16, 16, 128)  147584      ['re_lu_46[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_27 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_47 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_50[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 128)  512        ['re_lu_27[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 128)  512        ['re_lu_47[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 128)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 128)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 8, 8, 256)    295168      ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 8, 8, 256)    295168      ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " re_lu_28 (ReLU)                (None, 8, 8, 256)    0           ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_48 (ReLU)                (None, 8, 8, 256)    0           ['conv2d_51[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 8, 8, 256)    590080      ['re_lu_28[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 8, 8, 256)    590080      ['re_lu_48[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_29 (ReLU)                (None, 8, 8, 256)    0           ['conv2d_31[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_49 (ReLU)                (None, 8, 8, 256)    0           ['conv2d_52[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 8, 8, 256)    590080      ['re_lu_29[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 8, 8, 256)    590080      ['re_lu_49[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_30 (ReLU)                (None, 8, 8, 256)    0           ['conv2d_32[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_50 (ReLU)                (None, 8, 8, 256)    0           ['conv2d_53[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 8, 8, 256)    590080      ['re_lu_30[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 8, 8, 256)    590080      ['re_lu_50[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_31 (ReLU)                (None, 8, 8, 256)    0           ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_51 (ReLU)                (None, 8, 8, 256)    0           ['conv2d_54[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 8, 8, 256)   1024        ['re_lu_31[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 8, 8, 256)   1024        ['re_lu_51[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2DTran  (None, 16, 16, 128)  131200     ['batch_normalization_12[0][0]'] \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_transpose_6 (Conv2DTran  (None, 16, 16, 128)  131200     ['batch_normalization_17[0][0]'] \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_transpose_4[0][0]',     \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_transpose_6[0][0]',     \n",
            "                                                                  'batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 16, 16, 128)  295040      ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 16, 16, 128)  295040      ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " re_lu_32 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_52 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_55[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 16, 16, 128)  147584      ['re_lu_32[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 16, 16, 128)  147584      ['re_lu_52[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_33 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_35[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_53 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_56[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 16, 16, 128)  147584      ['re_lu_33[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 16, 16, 128)  147584      ['re_lu_53[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_34 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_36[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_54 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 16, 16, 128)  147584      ['re_lu_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 16, 16, 128)  147584      ['re_lu_54[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_35 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_37[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_55 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_58[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 128)  512        ['re_lu_35[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 16, 16, 128)  512        ['re_lu_55[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2DTran  (None, 32, 32, 64)  32832       ['batch_normalization_13[0][0]'] \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_transpose_7 (Conv2DTran  (None, 32, 32, 64)  32832       ['batch_normalization_18[0][0]'] \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 32, 32, 128)  0           ['conv2d_transpose_5[0][0]',     \n",
            "                                                                  'batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 32, 32, 128)  0           ['conv2d_transpose_7[0][0]',     \n",
            "                                                                  'batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 32, 32, 64)   73792       ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 32, 32, 64)   73792       ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " re_lu_36 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_56 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_59[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 32, 32, 64)   36928       ['re_lu_36[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 32, 32, 64)   36928       ['re_lu_56[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_37 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_39[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_57 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_60[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 32, 32, 64)   36928       ['re_lu_37[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 32, 32, 64)   36928       ['re_lu_57[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_38 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_40[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_58 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 32, 32, 64)   36928       ['re_lu_38[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 32, 32, 64)   36928       ['re_lu_58[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_39 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_41[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_59 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_62[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 32, 32, 64)  256         ['re_lu_39[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 32, 32, 64)  256         ['re_lu_59[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 32, 32, 1)    65          ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 32, 32, 1)    65          ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 32, 64, 1)    0           ['conv2d_42[0][0]',              \n",
            "                                                                  'conv2d_63[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,564,930\n",
            "Trainable params: 7,562,370\n",
            "Non-trainable params: 2,560\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "                  loss='mae',\n",
        "                  metrics=['mse'])\n",
        "display(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr7tzHe4fZmc"
      },
      "source": [
        "# Training the Model\n",
        "The model has been trained considering an EarlyStopping callback in order to avoid wasting time when the model tends to overfit and to recover the best obtained weights.\n",
        "In addition I used the ReduceLROnPlateu callback, starting from an initial value of `lr=1e-3`, with a reduction factor set to 0.5 in order to reduce the learning rate when the metric has stopped improving.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XV1OIT8ztOGz"
      },
      "outputs": [],
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, min_delta=1e-6, restore_best_weights=True)\n",
        "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",factor=0.5,patience=5,verbose=1,mode=\"min\",min_delta=1e-4,cooldown=0,min_lr=0,)\n",
        "my_callbacks = [es, lr]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPN00HfqtNQS"
      },
      "source": [
        "Then, the following settings regarding epochs,step_per_epochs and validation_steps were made."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Pp3qsfWfM_M",
        "outputId": "db129bcf-3c44-4543-ba22-2e66f20ff9dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "500/500 [==============================] - 64s 122ms/step - loss: 0.0379 - mse: 0.0131 - val_loss: 0.0155 - val_mse: 0.0027 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0140 - mse: 0.0022 - val_loss: 0.0104 - val_mse: 0.0014 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0107 - mse: 0.0015 - val_loss: 0.0094 - val_mse: 0.0013 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0098 - mse: 0.0012 - val_loss: 0.0084 - val_mse: 0.0011 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0092 - mse: 0.0011 - val_loss: 0.0135 - val_mse: 0.0016 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0089 - mse: 0.0010 - val_loss: 0.0088 - val_mse: 0.0010 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0080 - mse: 9.2327e-04 - val_loss: 0.0075 - val_mse: 8.9020e-04 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0077 - mse: 8.6585e-04 - val_loss: 0.0068 - val_mse: 7.7835e-04 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0076 - mse: 8.5644e-04 - val_loss: 0.0069 - val_mse: 8.0249e-04 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0071 - mse: 7.8190e-04 - val_loss: 0.0067 - val_mse: 8.2172e-04 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0072 - mse: 7.9550e-04 - val_loss: 0.0069 - val_mse: 8.0415e-04 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0070 - mse: 7.5015e-04 - val_loss: 0.0069 - val_mse: 7.1028e-04 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0072 - mse: 7.4508e-04 - val_loss: 0.0073 - val_mse: 7.6399e-04 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0067 - mse: 7.0887e-04 - val_loss: 0.0071 - val_mse: 7.7208e-04 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0063 - mse: 6.7626e-04 - val_loss: 0.0061 - val_mse: 7.1775e-04 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0068 - mse: 6.8536e-04 - val_loss: 0.0065 - val_mse: 7.2356e-04 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0063 - mse: 6.6356e-04 - val_loss: 0.0059 - val_mse: 6.7010e-04 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0064 - mse: 6.6794e-04 - val_loss: 0.0061 - val_mse: 6.3943e-04 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0063 - mse: 6.4088e-04 - val_loss: 0.0059 - val_mse: 6.3271e-04 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0062 - mse: 6.3519e-04 - val_loss: 0.0060 - val_mse: 6.2497e-04 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0062 - mse: 6.2971e-04 - val_loss: 0.0071 - val_mse: 7.3281e-04 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0059 - mse: 6.0539e-04\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0059 - mse: 6.0539e-04 - val_loss: 0.0066 - val_mse: 6.4600e-04 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0049 - mse: 5.4083e-04 - val_loss: 0.0050 - val_mse: 5.7293e-04 - lr: 5.0000e-04\n",
            "Epoch 24/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0050 - mse: 5.3674e-04 - val_loss: 0.0051 - val_mse: 5.7875e-04 - lr: 5.0000e-04\n",
            "Epoch 25/200\n",
            "500/500 [==============================] - 60s 121ms/step - loss: 0.0050 - mse: 5.2493e-04 - val_loss: 0.0051 - val_mse: 5.4165e-04 - lr: 5.0000e-04\n",
            "Epoch 26/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0049 - mse: 5.2416e-04 - val_loss: 0.0048 - val_mse: 5.3129e-04 - lr: 5.0000e-04\n",
            "Epoch 27/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0049 - mse: 5.2026e-04 - val_loss: 0.0050 - val_mse: 5.4438e-04 - lr: 5.0000e-04\n",
            "Epoch 28/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0050 - mse: 5.2666e-04 - val_loss: 0.0056 - val_mse: 5.5387e-04 - lr: 5.0000e-04\n",
            "Epoch 29/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0049 - mse: 5.1523e-04 - val_loss: 0.0054 - val_mse: 5.6746e-04 - lr: 5.0000e-04\n",
            "Epoch 30/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0052 - mse: 5.1912e-04 - val_loss: 0.0052 - val_mse: 5.5848e-04 - lr: 5.0000e-04\n",
            "Epoch 31/200\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0048 - mse: 5.1470e-04\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0048 - mse: 5.1470e-04 - val_loss: 0.0048 - val_mse: 5.1226e-04 - lr: 5.0000e-04\n",
            "Epoch 32/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0044 - mse: 4.7908e-04 - val_loss: 0.0045 - val_mse: 5.1988e-04 - lr: 2.5000e-04\n",
            "Epoch 33/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0044 - mse: 4.7657e-04 - val_loss: 0.0044 - val_mse: 4.7986e-04 - lr: 2.5000e-04\n",
            "Epoch 34/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0044 - mse: 4.7218e-04 - val_loss: 0.0043 - val_mse: 4.7631e-04 - lr: 2.5000e-04\n",
            "Epoch 35/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0044 - mse: 4.7529e-04 - val_loss: 0.0042 - val_mse: 4.5786e-04 - lr: 2.5000e-04\n",
            "Epoch 36/200\n",
            "500/500 [==============================] - 60s 121ms/step - loss: 0.0044 - mse: 4.6888e-04 - val_loss: 0.0044 - val_mse: 4.7746e-04 - lr: 2.5000e-04\n",
            "Epoch 37/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0044 - mse: 4.6979e-04 - val_loss: 0.0044 - val_mse: 4.6846e-04 - lr: 2.5000e-04\n",
            "Epoch 38/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0043 - mse: 4.6662e-04 - val_loss: 0.0043 - val_mse: 4.5720e-04 - lr: 2.5000e-04\n",
            "Epoch 39/200\n",
            "500/500 [==============================] - 60s 121ms/step - loss: 0.0043 - mse: 4.6275e-04 - val_loss: 0.0043 - val_mse: 4.7764e-04 - lr: 2.5000e-04\n",
            "Epoch 40/200\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0043 - mse: 4.6100e-04\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0043 - mse: 4.6100e-04 - val_loss: 0.0043 - val_mse: 4.6396e-04 - lr: 2.5000e-04\n",
            "Epoch 41/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0041 - mse: 4.4920e-04 - val_loss: 0.0042 - val_mse: 4.7899e-04 - lr: 1.2500e-04\n",
            "Epoch 42/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0041 - mse: 4.4876e-04 - val_loss: 0.0040 - val_mse: 4.3225e-04 - lr: 1.2500e-04\n",
            "Epoch 43/200\n",
            "500/500 [==============================] - 60s 121ms/step - loss: 0.0041 - mse: 4.4646e-04 - val_loss: 0.0043 - val_mse: 4.7905e-04 - lr: 1.2500e-04\n",
            "Epoch 44/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0041 - mse: 4.4797e-04 - val_loss: 0.0043 - val_mse: 4.7955e-04 - lr: 1.2500e-04\n",
            "Epoch 45/200\n",
            "500/500 [==============================] - 60s 121ms/step - loss: 0.0041 - mse: 4.4219e-04 - val_loss: 0.0042 - val_mse: 4.6292e-04 - lr: 1.2500e-04\n",
            "Epoch 46/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0041 - mse: 4.4300e-04 - val_loss: 0.0043 - val_mse: 4.9224e-04 - lr: 1.2500e-04\n",
            "Epoch 47/200\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0041 - mse: 4.4018e-04\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0041 - mse: 4.4018e-04 - val_loss: 0.0041 - val_mse: 4.5537e-04 - lr: 1.2500e-04\n",
            "Epoch 48/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0040 - mse: 4.3880e-04 - val_loss: 0.0042 - val_mse: 4.7554e-04 - lr: 6.2500e-05\n",
            "Epoch 49/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0040 - mse: 4.3864e-04 - val_loss: 0.0040 - val_mse: 4.5677e-04 - lr: 6.2500e-05\n",
            "Epoch 50/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0040 - mse: 4.3573e-04 - val_loss: 0.0040 - val_mse: 4.3729e-04 - lr: 6.2500e-05\n",
            "Epoch 51/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0040 - mse: 4.3724e-04 - val_loss: 0.0041 - val_mse: 4.5499e-04 - lr: 6.2500e-05\n",
            "Epoch 52/200\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0040 - mse: 4.3616e-04\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0040 - mse: 4.3616e-04 - val_loss: 0.0041 - val_mse: 4.7387e-04 - lr: 6.2500e-05\n",
            "Epoch 53/200\n",
            "500/500 [==============================] - 60s 121ms/step - loss: 0.0039 - mse: 4.3423e-04 - val_loss: 0.0040 - val_mse: 4.4958e-04 - lr: 3.1250e-05\n",
            "Epoch 54/200\n",
            "500/500 [==============================] - 60s 121ms/step - loss: 0.0039 - mse: 4.2899e-04 - val_loss: 0.0040 - val_mse: 4.3360e-04 - lr: 3.1250e-05\n",
            "Epoch 55/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.3110e-04 - val_loss: 0.0039 - val_mse: 4.2729e-04 - lr: 3.1250e-05\n",
            "Epoch 56/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.3504e-04 - val_loss: 0.0040 - val_mse: 4.6422e-04 - lr: 3.1250e-05\n",
            "Epoch 57/200\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0039 - mse: 4.3304e-04\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "500/500 [==============================] - 61s 122ms/step - loss: 0.0039 - mse: 4.3304e-04 - val_loss: 0.0041 - val_mse: 4.7012e-04 - lr: 3.1250e-05\n",
            "Epoch 58/200\n",
            "500/500 [==============================] - 61s 122ms/step - loss: 0.0039 - mse: 4.3032e-04 - val_loss: 0.0039 - val_mse: 4.3743e-04 - lr: 1.5625e-05\n",
            "Epoch 59/200\n",
            "500/500 [==============================] - 61s 122ms/step - loss: 0.0039 - mse: 4.2764e-04 - val_loss: 0.0039 - val_mse: 4.2449e-04 - lr: 1.5625e-05\n",
            "Epoch 60/200\n",
            "500/500 [==============================] - 61s 122ms/step - loss: 0.0039 - mse: 4.3190e-04 - val_loss: 0.0040 - val_mse: 4.5754e-04 - lr: 1.5625e-05\n",
            "Epoch 61/200\n",
            "500/500 [==============================] - 61s 122ms/step - loss: 0.0039 - mse: 4.3051e-04 - val_loss: 0.0040 - val_mse: 4.5535e-04 - lr: 1.5625e-05\n",
            "Epoch 62/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.3049e-04 - val_loss: 0.0040 - val_mse: 4.6535e-04 - lr: 1.5625e-05\n",
            "Epoch 63/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2699e-04 - val_loss: 0.0040 - val_mse: 4.5202e-04 - lr: 1.5625e-05\n",
            "Epoch 64/200\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0039 - mse: 4.2912e-04\n",
            "Epoch 64: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2912e-04 - val_loss: 0.0040 - val_mse: 4.3917e-04 - lr: 1.5625e-05\n",
            "Epoch 65/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2769e-04 - val_loss: 0.0040 - val_mse: 4.6348e-04 - lr: 7.8125e-06\n",
            "Epoch 66/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2654e-04 - val_loss: 0.0039 - val_mse: 4.4565e-04 - lr: 7.8125e-06\n",
            "Epoch 67/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2705e-04 - val_loss: 0.0042 - val_mse: 5.1223e-04 - lr: 7.8125e-06\n",
            "Epoch 68/200\n",
            "500/500 [==============================] - 61s 122ms/step - loss: 0.0039 - mse: 4.2920e-04 - val_loss: 0.0039 - val_mse: 4.4321e-04 - lr: 7.8125e-06\n",
            "Epoch 69/200\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0039 - mse: 4.2638e-04\n",
            "Epoch 69: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2638e-04 - val_loss: 0.0039 - val_mse: 4.3532e-04 - lr: 7.8125e-06\n",
            "Epoch 70/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2924e-04 - val_loss: 0.0040 - val_mse: 4.5085e-04 - lr: 3.9063e-06\n",
            "Epoch 71/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2823e-04 - val_loss: 0.0040 - val_mse: 4.5700e-04 - lr: 3.9063e-06\n",
            "Epoch 72/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2740e-04 - val_loss: 0.0039 - val_mse: 4.3366e-04 - lr: 3.9063e-06\n",
            "Epoch 73/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2465e-04 - val_loss: 0.0039 - val_mse: 4.2061e-04 - lr: 3.9063e-06\n",
            "Epoch 74/200\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0039 - mse: 4.2606e-04\n",
            "Epoch 74: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2606e-04 - val_loss: 0.0041 - val_mse: 4.8500e-04 - lr: 3.9063e-06\n",
            "Epoch 75/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2721e-04 - val_loss: 0.0039 - val_mse: 4.4630e-04 - lr: 1.9531e-06\n",
            "Epoch 76/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2771e-04 - val_loss: 0.0039 - val_mse: 4.4264e-04 - lr: 1.9531e-06\n",
            "Epoch 77/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2836e-04 - val_loss: 0.0039 - val_mse: 4.3278e-04 - lr: 1.9531e-06\n",
            "Epoch 78/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2928e-04 - val_loss: 0.0040 - val_mse: 4.5133e-04 - lr: 1.9531e-06\n",
            "Epoch 79/200\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0039 - mse: 4.2791e-04\n",
            "Epoch 79: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2791e-04 - val_loss: 0.0040 - val_mse: 4.7202e-04 - lr: 1.9531e-06\n",
            "Epoch 80/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2546e-04 - val_loss: 0.0040 - val_mse: 4.5043e-04 - lr: 9.7656e-07\n",
            "Epoch 81/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2516e-04 - val_loss: 0.0039 - val_mse: 4.3530e-04 - lr: 9.7656e-07\n",
            "Epoch 82/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2504e-04 - val_loss: 0.0039 - val_mse: 4.3475e-04 - lr: 9.7656e-07\n",
            "Epoch 83/200\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 0.0039 - mse: 4.2641e-04 - val_loss: 0.0040 - val_mse: 4.5213e-04 - lr: 9.7656e-07\n"
          ]
        }
      ],
      "source": [
        "steps_per_epoch=500\n",
        "validation_steps=10\n",
        "\n",
        "history=model.fit(\n",
        "    x=train_generator,\n",
        "    epochs=200,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    callbacks=my_callbacks,\n",
        "    validation_data = val_generator,\n",
        "    validation_steps = validation_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DTE7R-3fwLv"
      },
      "source": [
        "After training, I plot the results of the loss and of the mean_squared_error during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ApTvhVeXtGH2",
        "outputId": "d3b90b39-4445-4bec-dac6-ab1b5c196164"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"1dc2cb38-43ef-445b-9c7b-ad392dca9831\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1dc2cb38-43ef-445b-9c7b-ad392dca9831\")) {                    Plotly.newPlot(                        \"1dc2cb38-43ef-445b-9c7b-ad392dca9831\",                        [{\"mode\":\"lines+markers\",\"name\":\"loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83],\"y\":[0.03789118677377701,0.01401897706091404,0.010672623291611671,0.00978089403361082,0.00915506575256586,0.008879105560481548,0.007997896522283554,0.007692758925259113,0.007624828722327948,0.007065414916723967,0.0071810889057815075,0.006959480233490467,0.0071543436497449875,0.006653090473264456,0.00633031502366066,0.006777556147426367,0.0062937382608652115,0.006426852662116289,0.006268196739256382,0.006158101838082075,0.0061834934167563915,0.005878136493265629,0.004913694690912962,0.004998273681849241,0.005024382844567299,0.0049320426769554615,0.004923607688397169,0.004992816597223282,0.004869481548666954,0.005186749622225761,0.004775648005306721,0.004384065978229046,0.004387848544865847,0.004378803074359894,0.004371692426502705,0.004358117934316397,0.004362081177532673,0.004335148259997368,0.004346465226262808,0.0043161530047655106,0.004116665571928024,0.004104779567569494,0.004099335055798292,0.004104178864508867,0.0040778410620987415,0.00408898713067174,0.004057148937135935,0.003990791272372007,0.003994255792349577,0.003983379807323217,0.003975942265242338,0.003979385830461979,0.003946262877434492,0.003924746531993151,0.0039343819953501225,0.003941989503800869,0.003938661888241768,0.003909232094883919,0.0038993225898593664,0.003915759734809399,0.003919282928109169,0.0039042162243276834,0.0038904559332877398,0.00389872957020998,0.0038921390660107136,0.0038894894532859325,0.00387939577922225,0.003887814935296774,0.003878300543874502,0.0038821257185190916,0.00388570805080235,0.003875614842399955,0.0038703319150954485,0.0038713549729436636,0.003864345606416464,0.003873420413583517,0.003883205121383071,0.003880800912156701,0.003880094736814499,0.003860936965793371,0.0038662049919366837,0.003865661332383752,0.0038607607129961252],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"val_loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83],\"y\":[0.015474921092391014,0.010444341227412224,0.009364079684019089,0.008406820707023144,0.013501795940101147,0.008756345137953758,0.007527915295213461,0.006849495228379965,0.006871812045574188,0.00668078288435936,0.0069147562608122826,0.006862763315439224,0.0073324451223015785,0.007104679010808468,0.006097609177231789,0.006476343609392643,0.005946476012468338,0.006105103529989719,0.005929084494709969,0.0060296496376395226,0.007103572599589825,0.006567846983671188,0.005014900118112564,0.005084401927888393,0.00506814569234848,0.004846890922635794,0.005043432116508484,0.005631496664136648,0.005439768545329571,0.005174960941076279,0.004837085958570242,0.004471013322472572,0.004430057480931282,0.004307972267270088,0.004179111681878567,0.004374579526484013,0.004370986483991146,0.004333591554313898,0.00432626623660326,0.004272387363016605,0.004220862872898579,0.004030711483210325,0.004288260824978352,0.004290807526558638,0.0042219990864396095,0.00428509246557951,0.004142272286117077,0.004187519196420908,0.0040311249904334545,0.003964417148381472,0.004140509758144617,0.004129328764975071,0.003974120132625103,0.003991777077317238,0.003949461970478296,0.004035969730466604,0.004101070575416088,0.003938388079404831,0.003917183727025986,0.0039676777087152,0.00399872288107872,0.004034160636365414,0.004021836444735527,0.003955247811973095,0.0040073334239423275,0.0039234161376953125,0.004217654000967741,0.0039239670149981976,0.003891925560310483,0.003982845228165388,0.00398003775626421,0.0038833797443658113,0.003857038216665387,0.004058096557855606,0.003945068456232548,0.003930685110390186,0.003874851856380701,0.00395264383405447,0.004043987952172756,0.003951311111450195,0.0038588661700487137,0.0039357710629701614,0.0039771562442183495],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"loss during training\"},\"legend\":{\"title\":{\"text\":\"Losses\"}},\"xaxis\":{\"title\":{\"text\":\"Epochs\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1dc2cb38-43ef-445b-9c7b-ad392dca9831');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"f8dd38e8-8ca8-4ceb-9a3e-608aca1cd566\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f8dd38e8-8ca8-4ceb-9a3e-608aca1cd566\")) {                    Plotly.newPlot(                        \"f8dd38e8-8ca8-4ceb-9a3e-608aca1cd566\",                        [{\"mode\":\"lines+markers\",\"name\":\"mse\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83],\"y\":[0.013081532903015614,0.0021601305343210697,0.0014700250467285514,0.0012461416190490127,0.0011168307391926646,0.0010475125163793564,0.0009232661686837673,0.0008658534497953951,0.0008564427262172103,0.0007818986778147519,0.0007955009350553155,0.000750151404645294,0.0007450770353898406,0.0007088686106726527,0.0006762563134543598,0.000685357314068824,0.0006635601166635752,0.0006679448415525258,0.0006408810149878263,0.0006351866759359837,0.000629706250037998,0.0006053881370462477,0.0005408310098573565,0.0005367440171539783,0.0005249329842627048,0.0005241612670943141,0.0005202581523917615,0.000526655581779778,0.0005152349476702511,0.000519123743288219,0.000514704966917634,0.00047908350825309753,0.00047657443792559206,0.00047218467807397246,0.0004752900858875364,0.0004688788903877139,0.0004697876865975559,0.00046661781379953027,0.0004627467424143106,0.00046099614701233804,0.00044919538777321577,0.00044875647290609777,0.0004464625963009894,0.00044797491864301264,0.0004421887861099094,0.00044300357694737613,0.00044017782784067094,0.0004387972003314644,0.0004386416112538427,0.00043572677532210946,0.00043723912676796317,0.00043615527101792395,0.00043423115857876837,0.0004289892385713756,0.000431099470006302,0.0004350394883658737,0.00043303630081936717,0.00043032129178754985,0.000427643652074039,0.0004319034924264997,0.0004305063921492547,0.0004304943431634456,0.00042699402547441423,0.00042912468779832125,0.00042768678395077586,0.00042653625132516026,0.00042704615043476224,0.0004291994555387646,0.0004263835435267538,0.0004292391531635076,0.0004282270383555442,0.0004274040402378887,0.0004246541066095233,0.00042605603812262416,0.00042721297359094024,0.00042770669097080827,0.00042836336069740355,0.0004292780067771673,0.0004279051208868623,0.00042546429904177785,0.0004251605714671314,0.0004250435158610344,0.0004264095623511821],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"val_mse\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83],\"y\":[0.002692431677132845,0.0014471543254330754,0.001329226652160287,0.0011259897146373987,0.0016490512061864138,0.001026187906973064,0.00089019734878093,0.0007783483015373349,0.0008024877752177417,0.0008217175491154194,0.0008041459368541837,0.0007102809613570571,0.0007639872492291033,0.0007720778812654316,0.0007177540101110935,0.0007235563243739307,0.0006700963713228703,0.0006394262309186161,0.000632709008641541,0.0006249690195545554,0.0007328102365136147,0.0006460006698034704,0.0005729251424781978,0.000578753009904176,0.0005416477797552943,0.0005312947323545814,0.0005443777190521359,0.0005538720288313925,0.0005674640997312963,0.0005584770115092397,0.00051225780043751,0.000519883818924427,0.00047985586570575833,0.0004763119504787028,0.0004578586667776108,0.00047745677875354886,0.00046846139593981206,0.0004572044999804348,0.00047764359624125063,0.00046396302059292793,0.0004789912491105497,0.00043224653927609324,0.0004790463426616043,0.0004795470158569515,0.00046291755279526114,0.0004922406515106559,0.0004553701728582382,0.00047553936019539833,0.00045677326852455735,0.00043728650780394673,0.00045499467523768544,0.00047386749065481126,0.00044958069338463247,0.00043360493145883083,0.0004272920486982912,0.00046421829028986394,0.00047012409777380526,0.0004374342388473451,0.0004244917945470661,0.000457540329080075,0.00045534950913861394,0.0004653476062230766,0.00045201749890111387,0.00043917432776652277,0.00046348190517164767,0.00044564958079718053,0.0005122289876453578,0.00044320704182609916,0.00043532130075618625,0.00045085232704877853,0.00045699518523178995,0.0004336631973274052,0.0004206142039038241,0.0004850025288760662,0.0004462963552214205,0.0004426424275152385,0.0004327834176365286,0.00045132884406484663,0.00047201933921314776,0.0004504277021624148,0.0004352981341071427,0.00043475060374476016,0.00045212561963126063],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"mse during training\"},\"legend\":{\"title\":{\"text\":\"Losses\"}},\"xaxis\":{\"title\":{\"text\":\"Epochs\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f8dd38e8-8ca8-4ceb-9a3e-608aca1cd566');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_history(model_history,keys):\n",
        "  m,val_m= keys\n",
        "  history = model_history.history[m]\n",
        "  val_history = model_history.history[val_m]\n",
        "\n",
        "  df = pd.DataFrame(dict(\n",
        "      x = range(1,len(history)+1),\n",
        "      y = history, \n",
        "      y_1 = val_history,\n",
        "      ))\n",
        "\n",
        "  fig = go.Figure()\n",
        "  fig.add_trace(go.Scatter(x=df['x'], y=df['y'],\n",
        "                    mode='lines+markers',\n",
        "                    name= m))\n",
        "\n",
        "  fig.add_trace(go.Scatter(x=df['x'], y=df['y_1'],\n",
        "                    mode='lines+markers',\n",
        "                    name= val_m))\n",
        "\n",
        "  fig.update_layout(\n",
        "      title = m + ' during training',\n",
        "      legend_title='Losses',\n",
        "      xaxis_title = 'Epochs'\n",
        "      )\n",
        "\n",
        "  fig.update_xaxes()\n",
        "  fig.show()\n",
        "\n",
        "\n",
        "plot_history(history,['loss','val_loss'])\n",
        "plot_history(history,['mse','val_mse'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjvcj60nyfEt"
      },
      "source": [
        "*Loss* and *validation loss*, after a short period in which the val_loss fluctuates a bit, start drecrease together, showing that the model is learning and is not affected by overfitting. Also from the plot of *mse* and *val_mse*, we can see that the model has comparable performance on both train and validation datasets. \n",
        "So it can be seen also that the system starts to get good performance when training at about the 30th epoch. We are now going to save our results and see how the network behaves on a batch of photos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "tJydt6DSy6uH"
      },
      "outputs": [],
      "source": [
        "# cell to save weights after learning the net\n",
        "model.save_weights(\"exam_weights.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2RDmElSgYf-"
      },
      "source": [
        "# Model Testing and Conclusions\n",
        "Once the network is trained we can see how it behaves with the test data passed through the *test_generator*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "1yhapKQRfhmH",
        "outputId": "c640bc9c-8131-47a1-98c8-4c2a5aa4a724"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#getting predictions\n",
        "x_test,y_test=next(test_generator)\n",
        "y_pred=model.predict(x_test)\n",
        "\n",
        "#plot of input and predicted images\n",
        "plt.imshow(x_test[0],cmap='gray')\n",
        "plt.show()\n",
        "plt.imshow(y_test[0],cmap='gray')\n",
        "plt.show()\n",
        "plt.imshow(y_pred[0].reshape(32,64).astype(np.float32),cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clv3BMoq0v4E"
      },
      "source": [
        "It's possible to see that the predicted image it's pretty much the same as the real label image. Now, after defining the following functions for computing the results in terms of mse, we can evaluate the mse over 20000 samples and repeat the computation 10 times in order to check the standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_0YwhTRKgH2M"
      },
      "outputs": [],
      "source": [
        "def mse(y, y_pred):\n",
        "    m = ks.metrics.MeanSquaredError()\n",
        "    m.update_state(y, y_pred)\n",
        "    return m.result().numpy()\n",
        "\n",
        "def compute_metrics(original, noisy, metrics):\n",
        "    results = {}\n",
        "    for name, metric in metrics.items():\n",
        "        results[name] = metric(original, noisy)\n",
        "    return results\n",
        "\n",
        "def evaluate_model(model, x, y, metrics):\n",
        "    y_pred = model.predict(x) \n",
        "    x = x.astype('float32')\n",
        "    y_pred = y_pred.astype('float32')\n",
        "    y = y.astype('float32')\n",
        "  \n",
        "    results = mse(y,y_pred)\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYbS1s6sf3Xd",
        "outputId": "62474bac-7c85-45e9-8ab5-8960c37931be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.0004455631, 0.00044086485, 0.00043797263, 0.00043911606, 0.0004400878, 0.0004386296, 0.0004382626, 0.00043205376, 0.0004392267, 0.0004396286]\n",
            "mean:  0.00043914057\n",
            "std:  3.1302498e-06\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "for i in range(10):\n",
        "  x, y = next(test_generator)\n",
        "  results.append(evaluate_model(model, x, y, mse))\n",
        "\n",
        "print(results)\n",
        "\n",
        "print(\"mean: \", np.mean(results))\n",
        "print(\"std: \", np.std(results))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soX1icCPhrNm"
      },
      "source": [
        "In cocnlusion, with the double U-Net I reached very good values in terms of mean-squared-error and standard deviation indeed they are very small values. \n",
        "Furthermore, during various attempts I noticed how, by reloading the weights and performing new training sessions, the results improve reaching even the best value of mse equal to `3.8e-04` but then the network starts overfitting."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "Edoardo Conca.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
